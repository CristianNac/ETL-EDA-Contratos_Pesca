# AnÃ¡lisis de Contratos de Pesca

Proyecto de anÃ¡lisis de datos sobre empleo en plantas de procesamiento pesquero en Chile (2005-2011).

## ğŸ“‹ DescripciÃ³n

Este proyecto analiza los datos histÃ³ricos de empleo en plantas de procesamiento pesquero, proporcionando insights sobre la evoluciÃ³n del sector pesquero chileno durante el perÃ­odo 2005-2011.

## ğŸ—ï¸ Estructura del Proyecto

```
analisis-contratos-pesca/
â”œâ”€â”€ src/                          # CÃ³digo fuente
â”‚   â”œâ”€â”€ config/                   # Configuraciones
â”‚   â”‚   â”œâ”€â”€ data.py              # ConfiguraciÃ³n de datos
â”‚   â”‚   â””â”€â”€ db.py                # ConfiguraciÃ³n de base de datos
â”‚   â””â”€â”€ ETL/                     # Pipeline de datos
â”‚       â”œâ”€â”€ data/                # Archivos CSV (2005-2011)
â”‚       â”œâ”€â”€ extract.py           # ExtracciÃ³n de datos
â”‚       â”œâ”€â”€ transform.py         # TransformaciÃ³n de datos
â”‚       â””â”€â”€ persist.py           # Persistencia de datos
â”œâ”€â”€ notebooks-eda/              # AnÃ¡lisis exploratorio
â”‚   â””â”€â”€ eda_modelado_contratos.ipynb
â”œâ”€â”€ docker-compose.yml          # ConfiguraciÃ³n Docker
â”œâ”€â”€ Makefile                    # Comandos automatizados
â””â”€â”€ pyproject.toml             # Dependencias y configuraciÃ³n
```

## ğŸš€ InstalaciÃ³n

### Prerrequisitos
- Python 3.11+
- Poetry
- Docker (opcional)

### ConfiguraciÃ³n del entorno

1. **Clonar el repositorio**
   ```bash
   git clone <url-del-repositorio>
   cd analisis-contratos-pesca
   ```

2. **Instalar dependencias**
   ```bash
   poetry install
   ```

3. **Configurar variables de entorno**
   ```bash
   cp .env.example .env
   # Editar .env con tus configuraciones
   ```

## ğŸ”§ Uso

### Comandos disponibles (Makefile)

```bash
# Ver ayuda
make help

# Limpiar cache
make clean

# Revisar cÃ³digo con ruff
make lint

# Extraer datos desde CSV
make extract

# Transformar datos
make transform

# Ejecutar pipeline ETL completo
make etl
```

### Pipeline de datos

1. **ExtracciÃ³n**: Carga datos desde archivos CSV (2005-2011)
2. **TransformaciÃ³n**: Limpia y procesa los datos
3. **Persistencia**: Guarda en base de datos PostgreSQL

**Ejecutar pipeline completo:**
```bash
make etl  # Ejecuta todo el proceso ETL de una vez
```

## ğŸ“Š Datos

El proyecto trabaja con datos de empleo en plantas de procesamiento pesquero:
- **PerÃ­odo**: 2005-2011
- **Formato**: CSV con encoding latin-1
- **Separador**: punto y coma (;)

### Archivos de datos
- `empleoPlantasDeProceso2005.csv`
- `empleoPlantasDeProceso2006.csv`
- `empleoPlantasDeProceso2007.csv`
- `empleoPlantasDeProceso2008.csv`
- `empleoPlantasDeProceso2009.csv`
- `empleoPlantasDeProceso2010.csv`
- `empleoPlantasDeProceso2011.csv`

## ğŸ› ï¸ TecnologÃ­as

- **Python 3.11**: Lenguaje principal
- **Pandas**: ManipulaciÃ³n de datos
- **SQLAlchemy**: ORM para base de datos
- **Pydantic**: ValidaciÃ³n de configuraciones
- **PostgreSQL**: Base de datos (psycopg2-binary)
- **Ruff**: Linting y formateo
- **Poetry**: GestiÃ³n de dependencias
- **Docker**: ContainerizaciÃ³n

## ğŸ“ˆ AnÃ¡lisis

El notebook `eda_modelado_contratos.ipynb` contiene:
- AnÃ¡lisis exploratorio de datos
- Visualizaciones
- Modelado estadÃ­stico
- Insights del sector pesquero

## ğŸ¤ ContribuciÃ³n

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -am 'Agrega nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

## ğŸ‘¤ Autor

**Cristian Orellana**

---
